{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2\n",
    "\n",
    "# after you pull run `ollama run llama3.2`\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and even entire websites.\n",
      "2. **Marketing Automation**: AI-powered chatbots can help automate customer service, lead generation, and personalized marketing campaigns, providing a more efficient and effective way to engage with customers.\n",
      "3. **Design and Visualization**: Generative AI can be used to create 3D models, architecture designs, product designs, and even entire brand identities, reducing the time and cost associated with traditional design methods.\n",
      "4. **Personalized Recommendations**: Generative AI algorithms can analyze customer behavior and preferences to provide personalized product recommendations, improving user experience and increasing sales.\n",
      "5. **Data Analysis and Insights**: Generative AI can be used to analyze large datasets, identify patterns, and generate insights that help businesses make informed decisions.\n",
      "6. **Customer Service**: Generative AI-powered chatbots can provide 24/7 customer support, answering common questions, and routing complex issues to human representatives.\n",
      "7. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations, predicting demand, managing inventory, and streamlining logistics.\n",
      "8. **Product Design**: Generative AI can help designers create new products, such as fashion designs, by generating 3D models and prototypes, reducing the time and cost associated with traditional design methods.\n",
      "9. **Financial Modeling**: Generative AI can be used to generate financial models, forecasts, and scenarios, helping businesses make informed investment decisions.\n",
      "10. **Compliance and Risk Management**: Generative AI can help automate compliance and risk management tasks, such as monitoring regulatory changes, identifying potential risks, and generating alerts.\n",
      "\n",
      "Some examples of companies using generative AI in business include:\n",
      "\n",
      "* **Netflix** uses generative AI to create personalized content recommendations for its users.\n",
      "* **Amazon** uses generative AI to power its Alexa virtual assistant and provide personalized product suggestions.\n",
      "* **Procter & Gamble** uses generative AI to optimize supply chain operations and reduce costs.\n",
      "* **Google** uses generative AI to generate high-quality images, music, and text content.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases across various industries.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as product descriptions, social media posts, and articles. This can reduce the cost and time spent on creating content, while also increasing its consistency and quality.\n",
      "2. **Image and Video Generation**: Generative AI can generate realistic images and videos that can be used for various purposes such as marketing materials, advertising, and entertainment. For example, companies like Netflix use generative AI to create personalized movie recommendations and promotional content.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI is being used to build more sophisticated chatbots and virtual assistants that can understand natural language and provide personalized customer support.\n",
      "4. **Product Design and Development**: Generative AI can be used to generate design concepts for new products, reducing the time and cost associated with traditional design methods.\n",
      "5. **Marketing Analytics and Predictive Modeling**: Generative AI can be used to analyze customer data, identify trends, and predict future behavior. This information can be used to develop targeted marketing campaigns that drive more sales and revenue.\n",
      "6. **Finance and Risk Management**: Generative AI is being used in finance to identify potential risks and opportunities, analyze market trends, and optimize investment portfolios.\n",
      "7. **Healthcare and Biotech**: Generative AI is being used in healthcare to generate personalized medicine recommendations, develop new treatments, and accelerate clinical trials.\n",
      "8. **Supply Chain Optimization**: Generative AI can be used to optimize supply chains by predicting demand, identifying bottlenecks, and optimizing inventory management.\n",
      "9. **Customer Service and Support**: Generative AI-powered chatbots and virtual assistants are being used to provide 24/7 customer support and resolve issues quickly and efficiently.\n",
      "10. **Cybersecurity**: Generative AI can be used to detect and respond to cyber threats more effectively by analyzing patterns and anomalies in network traffic.\n",
      "\n",
      "Some specific business use cases that leverage generative AI include:\n",
      "\n",
      "* **Amazon's product recommendations**: Amazon uses generative AI to generate personalized product recommendations for its customers based on their browsing history, search queries, and purchasing habits.\n",
      "* **Sephora's virtual try-on**: Sephora uses generative AI to create a virtual try-on experience for its customers, allowing them to see how different products would look on themselves without physically attending a store.\n",
      "* **Netflix's content discovery**: Netflix uses generative AI to identify hidden gems and personalized content recommendations for its users based on their viewing history and preferences.\n",
      "* **DHL's supply chain optimization**: DHL uses generative AI to optimize supply chains by predicting demand, identifying bottlenecks, and optimizing inventory management.\n",
      "\n",
      "These are just a few examples of the many business applications that leverage generative AI. The potential use cases and applications continue to grow and expand as the technology improves and becomes more accessible.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n",
      "<think>\n",
      "Okay, so I need to understand the concepts behind large language models (LLMs), specifically focusing on what neural networks, attention mechanisms, and transformers are. Hmm, I've heard about NLP before, but I'm not exactly sure how all these pieces fit together.\n",
      "\n",
      "Let's start with neural networks because they seem pretty fundamental in LLMs. From what I remember, a neural network is a computational model inspired by the structure of the human brain's nervous system. It has layers like an input layer, hidden layers, and an output layer. Each node in these layers processes data through some kind of activation function. But how do they work exactly? Do they use weights and biases to make predictions or generate outputs?\n",
      "\n",
      "Then there's attention mechanisms. I think attention isn't something unique to LLMs; most models use a different kind for speech processing. Wait, in deep learning, the term \"attention\" is used more broadly. So maybe it refers to how each model focuses on specific parts of the input text, using self-attention and cross-attention. Self-attention processes a part of a token's embeddings with others from the same token, which helps focus on local context. Cross-attention then combines information across different tokens in sentences or entire documents.\n",
      "\n",
      "Moving on to transformers. This term has evolved a lot. Originally, I remember hearing that transformers were used in NLP for processing text sequences using self-attention mechanisms during training. So, during fine-tuning with data, the model attends to neighboring words and uses positional encodings to handle token order. But why do we need a separate architecture for inference? Because it's more efficient—no layers or hidden states needed. Only the input embeddings are used.\n",
      "\n",
      "When the model is trained on large datasets, does that mean all computations were done locally using GPUs or TPUs? Right, during training, each token and the model itself run the self-attention process in parallel. But for inference, since there's no shared GPU computing, the model processes tokens sequentially at inference time. Also, without layers or hidden states, it just needs embeddings concatenated into a single vector.\n",
      "\n",
      "So putting this all together: LLMs are neural networks that use attention mechanisms to focus on relevant parts of the input and different transformer architectures optimized for efficient text modeling with minimal resources.\n",
      "</think>\n",
      "\n",
      "Large Language Models (LLMs) are built using neural networks designed to process sequence data, such as text. Here's an organized overview focusing on neural networks, attention mechanisms, and transformers:\n",
      "\n",
      "1. **Neural Networks**:\n",
      "   - Neural networks are computational models inspired by the brain's structure and function, resembling a series of layered nodes: input, hidden (repeated layers), and output.\n",
      "   - Each node processes data through activation functions to make predictions or generate responses through outputs.\n",
      "\n",
      "2. **Attention Mechanisms**:\n",
      "   - These mechanisms enable models to focus on specific parts of their inputs, addressing context-specific dependencies.\n",
      "   - Used across various NLP tasks. It includes:\n",
      "     - **Self-Attention**: Focuses on local context within the same token (e.g., \"this cat's hat\"). Processed in pairs to understand neighboring words.\n",
      "     - **Cross-Attention**: Combines information from different tokens using a shared embedding space, crucial for multi-sentences or documents.\n",
      "\n",
      "3. **Transformer Architecture**:\n",
      "   - Originally introduced in language models, it uses self-attention during training.\n",
      "   - **Self-Attention**: For within-token context processing, applying neural attention mechanisms learned during fine-tuning on large datasets with the GPU/TPU for parallel computation.\n",
      "   - **Efficiency at Inference**: Disjointed by a token embedding vector, processed sequentially without shared resources. No additional layers or hidden states needed.\n",
      "\n",
      "In summary, LLMs leverage neural networks, attention mechanisms, and Transformers. They use self-attention for local context in training and efficient inference using tokens sequentially with precomputed embeddings for tasks beyond their training input.\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit - The heart of the internet\n"
     ]
    }
   ],
   "source": [
    "result = Website(\"https://www.reddit.com/\")\n",
    "print(result.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website): \n",
    "    prompt = user_prompt_for(website)\n",
    "    if not prompt:\n",
    "        raise ValueError(\"user_prompt_for(website) returned an empty string!\")\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the Ollama function instead of OpenAI\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    messages = messages_for(website)\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is a post from the subreddit r/RelationshipsAmI, where users share stories and ask for advice on their relationships. The user shares a story about a recent conflict with her partner, who she claims has a history of being aggressive and mocking her.\n",
       "\n",
       "The user describes how they went to celebrate a career milestone together, but the partner's family was present and he became focused on making them laugh at her expense. She claims that he paid for the cake and then smashed it on the floor, calling it \"funny.\" When she tried to leave or apologize, he said that his mother felt humiliated by her reaction.\n",
       "\n",
       "The user is now wondering if they were justified in slapping him (she didn't actually slap him) and asking for advice from others. They've blocked their partner and are seeking validation on whether their behavior was reasonable under the circumstances.\n",
       "\n",
       "Some potential issues with this story:\n",
       "\n",
       "1. The user's behavior: While it's understandable to want to protect oneself from hurtful comments, slapping someone is a physical act that can escalate conflicts.\n",
       "2. The power dynamic: The user's partner has a history of being aggressive and mocking her, which could create an imbalance in the relationship. This might have led to feelings of frustration or defensiveness in the user.\n",
       "3. The timing and context: Celebrating a career milestone with someone who is prone to mockery and aggression might not be the best idea.\n",
       "\n",
       "Some potential questions to consider:\n",
       "\n",
       "* Was the partner's behavior truly hurtful or was it just an attempt to make his family laugh?\n",
       "* Did the user's reaction (slapping) seem proportionate to the situation, or was it a dramatic overreaction?\n",
       "* Is there a deeper issue in the relationship that needs to be addressed before conflicts like this arise?\n",
       "\n",
       "The final verdict will depend on individual perspectives and values. Some might see the user's behavior as justified, while others might think it was an overreaction or even a sign of larger relationship issues."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "\n",
    "display_summary(\"https://reddit.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool to answer any technical questions related to software engineering using Ollama 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Please explain how do you solve the prime numbers in Java efficiently\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"you are a programming expert who answers questions about python, java, software engineering, LLMs and Data science\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please give details explanations of the followig question:\" + question}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Solving Prime Numbers in Java Efficiently\n",
       "=====================================\n",
       "\n",
       "Prime numbers are a fundamental concept in number theory, and they have numerous applications in various fields, such as cryptography, coding theory, and computer science. In this explanation, we'll discuss an efficient algorithm to find prime numbers in Java.\n",
       "\n",
       "**Overview of the Problem**\n",
       "\n",
       "Given a range of integers, we want to identify all prime numbers within that range. A prime number is a positive integer greater than 1 that has no positive divisors other than 1 and itself.\n",
       "\n",
       "**Approach: Sieve of Eratosthenes Algorithm**\n",
       "\n",
       "The most efficient algorithm for finding prime numbers up to a given limit is the Sieve of Eratosthenes. This algorithm works by iteratively marking as composite (not prime) the multiples of each prime number as it is encountered.\n",
       "\n",
       "Here's why this approach is efficient:\n",
       "\n",
       "*   It only requires a single pass through the range of integers.\n",
       "*   It uses a minimum amount of memory, making it suitable for large ranges.\n",
       "*   It is relatively simple to implement.\n",
       "\n",
       "**Java Implementation**\n",
       "\n",
       "```java\n",
       "public class SieveOfEratosthenes {\n",
       "\n",
       "    /**\n",
       "     * Finds all prime numbers up to the given limit using the Sieve of Eratosthenes algorithm.\n",
       "     *\n",
       "     * @param limit The upper bound (inclusive) for finding prime numbers.\n",
       "     * @return A list of prime numbers within the specified range.\n",
       "     */\n",
       "    public static List<Integer> findPrimes(int limit) {\n",
       "        boolean[] primes = new boolean[limit + 1];\n",
       "        primes[0] = primes[1] = false;\n",
       "\n",
       "        // Iterate from 2 to sqrt(limit)\n",
       "        for (int p = 2; p * p <= limit; p++) {\n",
       "            if (primes[p]) {\n",
       "                // Mark as composite all multiples of p\n",
       "                for (int i = p * p; i <= limit; i += p) {\n",
       "                    primes[i] = true;\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "\n",
       "        // Return a list of prime numbers within the specified range\n",
       "        List<Integer> result = new ArrayList<>();\n",
       "        for (int p = 0; p < limit; p++) {\n",
       "            if (!primes[p]) {\n",
       "                result.add(p);\n",
       "            }\n",
       "        }\n",
       "        return result;\n",
       "    }\n",
       "\n",
       "    public static void main(String[] args) {\n",
       "        int limit = 100;\n",
       "        List<Integer> primes = findPrimes(limit);\n",
       "        System.out.println(\"Prime numbers up to \" + limit + \": \" + primes);\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "**Explanation of the Code**\n",
       "\n",
       "The code implements the Sieve of Eratosthenes algorithm as follows:\n",
       "\n",
       "1.  We create a boolean array `primes` with size `limit + 1`, where `primes[i]` represents whether `i` is prime or not.\n",
       "2.  We initialize all elements to `false`, except for `0` and `1`, which are not prime numbers by definition.\n",
       "3.  We iterate from 2 to the square root of `limit`. For each prime number `p` in this range:\n",
       "    *   If `p` is marked as prime (`primes[p] == true`), we mark all its multiples `i` (starting from `p * p`) as composite by setting `primes[i] = true`.\n",
       "4.  Finally, we create a list of all prime numbers within the specified range by iterating through the `primes` array and adding indices with `false` values to the result list.\n",
       "5.  In the `main` method, we demonstrate how to use this implementation to find prime numbers up to a given limit.\n",
       "\n",
       "**Time Complexity**\n",
       "\n",
       "The time complexity of the Sieve of Eratosthenes algorithm is O(n log log n), where n is the upper bound of the range. This makes it an efficient solution for finding prime numbers within large ranges.\n",
       "\n",
       "**Space Complexity**\n",
       "\n",
       "The space complexity of this implementation is O(n), as we need to store a boolean array with size `limit + 1` to keep track of prime numbers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "reply = response['message']['content']\n",
    "display(Markdown(reply))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
